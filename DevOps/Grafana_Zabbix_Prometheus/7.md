# Logstash Nedir?

BiliÅŸim sistemleri, sÃ¼rekli olarak log Ã¼retmektedir. Bu loglarda; hata tespiti, gÃ¼venlik analizi ve performans iyileÅŸtirme gibi birÃ§ok alanda hayati Ã¶neme sahiptir. Ancak bu loglarÄ±n anlamlÄ± hale getirilmesi zordur. Logstash ise log verilerini iÅŸler, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r iÅŸler ve merkezi sistemlere gÃ¶ndererek deÄŸer Ã¼retmemizi saÄŸlar.

![Logstash](./img/logstash.png)

Logstash, Elastic Stack'Ä±n bir parÃ§asÄ±dÄ±r. Ana gÃ¶revleri:

* Veriyi alÄ±p (Input),
* Ä°ÅŸleyip dÃ¶nÃ¼ÅŸtÃ¼rerek (Filter),
* Belirli yerlere aktarÄ±lmasÄ± (Output).

Logstash Mimarisi Ã¼Ã§ temel bÃ¶lÃ¼mden oluÅŸur:

* Input	
* Filter
* Output

![Logstash](./img/Logstash_Mimarisi.png)

| BileÅŸen    | GÃ¶rev                                                                    |
| ---------- | ------------------------------------------------------------------------ |
| **Input**  | Veriyi farklÄ± kaynaklardan alÄ±r (dosya, TCP, syslog, beats, Kafka vb.)   |
| **Filter** | Veriyi iÅŸler, temizler, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (Ã¶rneÄŸin grok ile parse iÅŸlemi)       |
| **Output** | Veriyi Elasticsearch, dosya, stdout, e-posta, Kafka vb. yerlere gÃ¶nderir |

Logstash 'Ä±n yapÄ±sÄ±nÄ±n ve kullanÄ±mÄ±nÄ±n daha iyi anlaÅŸÄ±lmasÄ± amacÄ±yla aÅŸaÄŸÄ±daki uygulamaya geÃ§elim.

## Uygulama - Logstash ile Log Analizi

Bu uygulama da python kullanarak log Ã¼reteceÄŸiz. Ãœretilen loglarÄ±n Logstash tarafÄ±ndan iÅŸlenmesini saÄŸlamaktÄ±r. Bu uygulamadaki amaÃ§larÄ±mÄ±z;

* Ã–zel bir uygulama, her saniye bir log Ã¼retir.
* Logstash bu loglarÄ± okur, iÅŸler ve Elasticsearchâ€™e yollar.
* Verileri kontrol etmek iÃ§in Python ile Elasticsearch APIâ€™sini kullanacaÄŸÄ±z.

Uygulama ortamÄ±nÄ±n oluÅŸturulmasÄ± amacÄ±yla aÅŸaÄŸÄ±daki proje oluÅŸturulur.

**Proje YapÄ±sÄ±**

```
elk-logs/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ log-producer/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ logstash/
â”‚   â””â”€â”€ logstash.conf
```

**log-producer/app.py** â€“ Ã–zel Log Ãœreticisi

```python
import time
import logging
import random
import os

# Log klasÃ¶rÃ¼ yoksa oluÅŸtur
os.makedirs("/logs", exist_ok=True)

# logging formatÄ±nda 'log_message' kullandÄ±k, 'message' DEÄÄ°L
logging.basicConfig(
    filename="/logs/app.log",
    format="%(asctime)s - %(levelname)s - user:%(user)s - message:%(log_message)s",
    level=logging.INFO
)

users = ['alice', 'bob', 'charlie']
messages = ['Login successful', 'Logout', 'Error occurred', 'Data saved']

while True:
    log_data = {
        "user": random.choice(users),
        "log_message": random.choice(messages)  # â—ï¸BurasÄ± Ã–NEMLÄ°: 'message' deÄŸil
    }
    logging.info("event", extra=log_data)
    time.sleep(1)

```

**logstash/logstash.conf**

```conf
input {
  file {
    path => "/logs/app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - user:%{WORD:user} - message:%{GREEDYDATA:custom_message}" }
  }
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "app_logs"
  }
  stdout { codec => rubydebug }
}
```

**docker-compose.yml**

```yml
version: '3.7'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.9.1
    container_name: logstash
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logs:/logs
    depends_on:
      - elasticsearch

  log-producer:
    build:
      context: ./log-producer
    command: ["sleep", "360000"]
    volumes:
      - ./logs:/logs
      - ./log-producer/:/app/

```

**log-producer/Dockerfile**

```Dockerfile
FROM python:3.11
WORKDIR /app
COPY app.py .
RUN mkdir /logs
CMD ["python", "app.py"]
```

Sistemin baÅŸlatÄ±lmasÄ± amacÄ±yla ``docker-compose up --build`` komutu kullanÄ±lÄ±r. ``log-producer`` adlÄ± container'a bash olarak login olunur ve ``python3 app.py`` komutu kullanÄ±lÄ±r ve log oluÅŸturma iÅŸlemi baÅŸlatÄ±lÄ±r. Sistem baÅŸlatÄ±ldÄ±ktan sonra sistemin kontrol edilmesi amacÄ±yla aÅŸaÄŸÄ±daki kodu kullabilirsiniz;

**check.py**

```python
import requests
import time

# Elasticsearch hazÄ±r olduÄŸunda Ã§alÄ±ÅŸmasÄ± iÃ§in bekleme
time.sleep(10)

url = "http://elasticsearch:9200/app_logs/_search"
payload = {
    "size": 5,
    "sort": [{"@timestamp": "desc"}]
}

res = requests.get(url, json=payload)
for hit in res.json()["hits"]["hits"]:
    print(hit["_source"])
```

Bu kod ile Elasticsearch iÃ§indeki app_logs adlÄ± index'ten en son 5 log kaydÄ±nÄ± Ã§ekip terminalde yazdÄ±rÄ±r. Buradan elde edilen loglarÄ±n Elasticsearch iletildiÄŸini anlamaktayÄ±z.

![Logstash](./img/86.png)

EÄŸer istenirse Log seviyelerine gÃ¶re **farklÄ± indexlere** yÃ¶nlendirebiliriz. (Ã¶rneÄŸin INFO â†’ info_logs, ERROR â†’ error_logs).
Bu iÅŸlem iÃ§in;

**logstash/logstash.conf**

```yml
input {
  file {
    path => "/logs/app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:level} - user:%{WORD:user} - message:%{GREEDYDATA:custom_message}" }
  }
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  if [level] == "INFO" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "info_logs"
    }
  } else if [level] == "ERROR" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "error_logs"
    }
  } else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "general_logs"
    }
  }

  stdout { codec => rubydebug }
}
```

**app.py**

```python
import time
import logging
import random
import os

# Log klasÃ¶rÃ¼ yoksa oluÅŸtur
os.makedirs("/logs", exist_ok=True)

# Log formatÄ± ('log_message' alanÄ±nÄ± kullanÄ±yoruz)
logging.basicConfig(
    filename="/logs/app.log",
    format="%(asctime)s - %(levelname)s - user:%(user)s - message:%(log_message)s",
    level=logging.INFO
)

users = ['alice', 'bob', 'charlie']
messages = ['Login successful', 'Logout', 'Error occurred', 'Data saved', 'Critical failure']

while True:
    msg = random.choice(messages)
    level = logging.ERROR if 'Error' in msg or 'Critical' in msg else logging.INFO

    log = {
        "user": random.choice(users),
        "log_message": msg  # â— 'message' deÄŸil 'log_message'
    }

    logging.log(level, "event", extra=log)
    time.sleep(1)

```

YapÄ±lan bu iÅŸlemin doÄŸruluÄŸunun kontrol edilmesi amacÄ±yla aÅŸaÄŸÄ±daki python kodu kullanÄ±labilir;

```python
import requests
import time

time.sleep(10)

def check_logs(index):
    url = f"http://elasticsearch:9200/{index}/_search"
    payload = {
        "size": 3,
        "sort": [{"@timestamp": "desc"}]
    }

    res = requests.get(url, json=payload)
    if res.status_code == 200:
        hits = res.json()["hits"]["hits"]
        print(f"\nğŸ“ {index} - Son 3 kayÄ±t:")
        for h in hits:
            print(h["_source"])
    else:
        print(f"Hata: {res.text}")

check_logs("info_logs")
check_logs("error_logs")
```

Bu kodun amacÄ± Elasticsearch iÃ§indeki iki farklÄ± index olan ``info_logs`` ve ``error_logs`` iÃ§in son 3 log kaydÄ±nÄ± Ã§ekmek ve terminale yazdÄ±rmak.

![Logstash](./img/87.png)

Åimdi bu sistemi bir Ã¼st versiona taÅŸÄ±yalÄ±m **structured logging (yapÄ±landÄ±rÄ±lmÄ±ÅŸ JSON loglama)** kullanarak:

* Uygulama loglarÄ±nÄ± JSON formatÄ±nda yazacaÄŸÄ±z.
* Logstash bu JSON verilerini otomatik olarak parse edecek.
* Logstash filtresi sadeleÅŸecek, Ã§Ã¼nkÃ¼ veri zaten yapÄ±landÄ±rÄ±lmÄ±ÅŸ olacak.
* Elasticsearch'e doÄŸrudan anlamlÄ± veri gidecek.
* Python ile loglarÄ± Ã§ekip analiz yapacaÄŸÄ±z.

Bu iÅŸlem iÃ§in gerekli gÃ¼ncellemelerin gerÃ§ekleÅŸtirilmelidir.

**log-producer/app.py**

```python
import time
import json
from datetime import datetime
import random

users = ['alice', 'bob', 'charlie']
messages = ['Login successful', 'Logout', 'Error occurred', 'Data saved', 'Critical failure']

with open('/logs/app.log', 'a') as f:
    while True:
        msg = random.choice(messages)
        level = 'ERROR' if 'Error' in msg or 'Critical' in msg else 'INFO'
        log = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": level,
            "user": random.choice(users),
            "message": msg
        }
        f.write(json.dumps(log) + '\n')
        f.flush()
        time.sleep(1)
```

**logstash.conf**

```yml
input {
  file {
    path => "/logs/app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
  }
}

filter {
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  if [level] == "INFO" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "json_info_logs"
    }
  } else if [level] == "ERROR" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "json_error_logs"
    }
  } else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "json_other_logs"
    }
  }

  stdout { codec => rubydebug }
}
```

Bu iÅŸlemin check edilmesi amacÄ±yla ``json_check.py`` dosyasÄ± kullanÄ±lÄ±r. 

**json_check.py**
```python
import requests
import time

time.sleep(10)

def check_json_logs(index):
    url = f"http://elasticsearch:9200/{index}/_search"
    payload = {
        "size": 5,
        "sort": [{"@timestamp": "desc"}]
    }

    res = requests.get(url, json=payload)
    print(f"\nğŸ“‚ {index} - Son 5 kayÄ±t:")
    for hit in res.json()["hits"]["hits"]:
        print(hit["_source"])

check_json_logs("json_info_logs")
check_json_logs("json_error_logs")

def count_logs_by_user(index):
    url = f"http://elasticsearch:9200/{index}/_search"
    payload = {
        "size": 0,
        "aggs": {
            "by_user": {
                "terms": {"field": "user.keyword"}
            }
        }
    }

    res = requests.get(url, json=payload)
    print(f"\nğŸ‘¤ KullanÄ±cÄ± bazlÄ± sayÄ±m ({index}):")
    for bucket in res.json()["aggregations"]["by_user"]["buckets"]:
        print(f"{bucket['key']}: {bucket['doc_count']} log")

count_logs_by_user("json_info_logs")

```
Bu Python kodu, Elasticsearchâ€™teki log indexâ€™lerinden veri Ã§ekmek ve analiz yapmak iÃ§in yazÄ±lmÄ±ÅŸtÄ±r. Kodun iÅŸlevi;

* ``json_info_logs`` ve ``json_error_logs`` indexâ€™lerinden **son 5 log kaydÄ±nÄ±** yazdÄ±rmak
* ``json_info_logs`` indexâ€™inde kullanÄ±cÄ± **bazlÄ± log sayÄ±mÄ±nÄ±** gÃ¶stermek

![Logstash](./img/88.png)


Bu iÅŸlemin ardÄ±ndan loglara IP adresi ekleyeceÄŸiz, Logstash bu IPâ€™yi kullanarak konum bilgisi (Ã¼lke, ÅŸehir, koordinat) Ã§Ä±karacak ve Elasticsearchâ€™e bu bilgileri de gÃ¶nderecek. Bu iÅŸlemin gerÃ§ekleÅŸtirilmesi iÃ§in aÅŸaÄŸÄ±daki gÃ¼ncellemeleri gerÃ§ekleÅŸtirmeliyiz.


**log-producer/app.py**

```python
import time
import json
from datetime import datetime
import random

users = ['alice', 'bob', 'charlie']
messages = ['Login successful', 'Logout', 'Error occurred', 'Data saved', 'Critical failure']
ips = ['8.8.8.8', '1.1.1.1', '185.60.216.35', '203.0.113.10']  # Ã–rnek IP'ler

with open('/logs/app.log', 'a') as f:
    while True:
        msg = random.choice(messages)
        level = 'ERROR' if 'Error' in msg or 'Critical' in msg else 'INFO'
        log = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": level,
            "user": random.choice(users),
            "message": msg,
            "ip": random.choice(ips)
        }
        f.write(json.dumps(log) + '\n')
        f.flush()
        time.sleep(1)
```

**logstash/logstash.conf** - Filter bÃ¶lÃ¼mÃ¼ eklenir

```yml
filter {
  if [ip] {
    geoip {
      source => "ip"
      target => "[geoip]"  # ğŸ’¡ GeoIP bilgileri bu alana yazÄ±lacak
    }
  }

  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}
```

Bu gÃ¼ncellemelerin ardÄ±ndan sistem sistem yeniden baÅŸlatÄ±lÄ±r. Sistemin kontrol edilmesi amacÄ±yla aÅŸaÄŸÄ±daki python kodunu kullanabilirsiniz;

```python
import requests
import time

time.sleep(10)

def show_geoip_logs(index):
    url = f"http://elasticsearch:9200/{index}/_search"
    payload = {
        "size": 5,
        "sort": [{"@timestamp": "desc"}]
    }

    res = requests.get(url, json=payload)
    
    if res.status_code == 200:
        print(f"\nğŸ“ GeoIP kontrollÃ¼ kayÄ±tlar ({index}):")
        for hit in res.json()["hits"]["hits"]:
            source = hit["_source"]
            ip = source.get('ip', 'â“ IP yok')
            country = source.get('geoip', {}).get('country_name', 'â“ Ãœlke yok')
            city = source.get('geoip', {}).get('city_name', 'â“ Åehir yok')
            print(f"{ip} â¡ {country} - {city}")
    else:
        print(f"âŒ Hata: {res.status_code} - {res.text}")

show_geoip_logs("json_info_logs")

```

![Logstash](./img/89.png)

Bu sistemi **threshold tabanlÄ± uyarÄ± sistemi** haline getirebiliriz. Bu yeni sistemde hedefimiz;

* AynÄ± kullanÄ±cÄ± veya aynÄ± IP, kÄ±sa sÃ¼rede 3 veya daha fazla ERROR logu Ã¼retirse Python ile bunu tespit edeceÄŸiz.
* UyarÄ±nÄ±n console yazÄ±lmasÄ± saÄŸlanacaktÄ±r. (EÄŸer istenirse smtp ile mail olarak iletilebilir.)

Bu iÅŸlem iÃ§in kullanÄ±lacak python script'i kullanÄ±labilir.

```python
import requests
from datetime import datetime, timedelta
from collections import defaultdict

# 15 dakika Ã¶ncesi
time_range_start = (datetime.utcnow() - timedelta(minutes=15)).isoformat()

url = "http://elasticsearch:9200/json_error_logs/_search"
payload = {
    "size": 1000,
    "query": {
        "range": {
            "@timestamp": {
                "gte": time_range_start
            }
        }
    }
}

res = requests.get(url, json=payload)
if res.status_code != 200:
    print("Elasticsearch baÄŸlantÄ± hatasÄ±:", res.text)
    exit()

hits = res.json()["hits"]["hits"]

# KullanÄ±cÄ± ve IP bazlÄ± log sayÄ±mÄ±
user_errors = defaultdict(int)
ip_errors = defaultdict(int)

for hit in hits:
    source = hit["_source"]
    user = source.get("user", "unknown")
    ip = source.get("ip", "unknown")
    user_errors[user] += 1
    ip_errors[ip] += 1

# UyarÄ± eÅŸikleri
threshold = 3

print("ğŸš¨ UyarÄ±lar (son 15 dakika):")
for user, count in user_errors.items():
    if count >= threshold:
        print(f"âš ï¸  KullanÄ±cÄ± '{user}' â†’ {count} ERROR logu oluÅŸturdu")

for ip, count in ip_errors.items():
    if count >= threshold:
        print(f"âš ï¸  IP '{ip}' â†’ {count} ERROR logu oluÅŸturdu")
```

![Logstash](./img/90.png)


Åimdide Elasticsearch Ã¼zerinden alÄ±nan verilerin gÃ¶rselleÅŸtirelim. Bu iÅŸlem iÃ§in Flask tabanlÄ± sade bir web arayÃ¼zÃ¼ kullanacaÄŸÄ±z. Bunun Ã¶ncesinde log Ã¼retecek olan python kodu ve ``logstash.conf`` aÅŸaÄŸÄ±daki gibidir;

**logstash.conf**

```conf
input {
  file {
    path => "/logs/app.log"
    codec => json
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  geoip {
    source => "ip"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "json_error_logs"
  }
  stdout { codec => rubydebug }
}
```

**app_log_producer.py**

```python
import time
import json
from datetime import datetime
import random
import os

LOG_DIR = "/logs"
LOG_FILE = os.path.join(LOG_DIR, "app.log")

# Dosya klasÃ¶rÃ¼ oluÅŸtur
os.makedirs(LOG_DIR, exist_ok=True)

users = ["alice", "bob", "charlie"]
messages = [
    "Login successful",
    "Logout",
    "Error occurred",
    "Data saved",
    "Access denied",
    "Session expired",
    "Critical failure"
]
ips = ["8.8.8.8", "1.1.1.1", "185.60.216.35", "203.0.113.10"]

while True:
    msg = random.choice(messages)
    level = "ERROR" if "Error" in msg or "Critical" in msg or "denied" in msg else "INFO"

    log_entry = {
        "timestamp": datetime.utcnow().isoformat(),
        "level": level,
        "user": random.choice(users),
        "message": msg,
        "ip": random.choice(ips)
    }

    with open(LOG_FILE, "a") as log_file:
        log_file.write(json.dumps(log_entry) + "\n")

    print(f"âœ… Yeni log yazÄ±ldÄ±: {log_entry}")
    time.sleep(5)
```

Flask web kodlarÄ± aÅŸaÄŸÄ±daki gibidir;

**Flask Web Dizin YapÄ±sÄ±**

```
log-monitor/
â”œâ”€â”€ app.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ â””â”€â”€ errors.html
â”œâ”€â”€ â””â”€â”€ chart.html
```

**app.py**

```python
from flask import Flask, render_template, request
import requests

app = Flask(__name__)
ELASTIC_URL = "http://elasticsearch:9200/json_error_logs/_search"

@app.route("/", methods=["GET"])
def index():
    query = request.args.get("q", "")
    user = request.args.get("user", "")
    level = request.args.get("level", "")

    # Elasticsearch query
    filters = []
    if query:
        filters.append({"match": {"message": query}})
    if user:
        filters.append({"match": {"user": user}})
    if level:
        filters.append({"match": {"level": level}})

    search_query = {
        "size": 50,
        "sort": [{"@timestamp": "desc"}],
        "query": {
            "bool": {
                "must": filters if filters else [{"match_all": {}}]
            }
        }
    }

    res = requests.get(ELASTIC_URL, json=search_query)
    if res.status_code == 200:
        logs = [hit["_source"] for hit in res.json()["hits"]["hits"]]
    else:
        logs = []

    return render_template("index.html", logs=logs, query=query, user=user, level=level)

@app.route("/errors", methods=["GET"])
def error_logs():
    user = request.args.get("user", "")
    ip = request.args.get("ip", "")

    filters = [{"match": {"level": "ERROR"}}]

    if user:
        filters.append({"match": {"user": user}})
    if ip:
        filters.append({"match": {"ip": ip}})

    query = {
        "size": 100,
        "sort": [{"@timestamp": "desc"}],
        "query": {
            "bool": {
                "must": filters
            }
        }
    }

    res = requests.get(ELASTIC_URL, json=query)
    logs = [hit["_source"] for hit in res.json()["hits"]["hits"]] if res.status_code == 200 else []

    return render_template("errors.html", logs=logs, user=user, ip=ip)


@app.route("/error-chart")
def error_chart():
    url = "http://elasticsearch:9200/json_error_logs/_search"

    payload = {
        "size": 0,
        "query": {
            "match": {
                "level": "ERROR"
            }
        },
        "aggs": {
            "users": {
                "terms": {
                    "field": "user.keyword",
                    "size": 10
                }
            }
        }
    }

    res = requests.get(url, json=payload)
    buckets = res.json()["aggregations"]["users"]["buckets"] if res.status_code == 200 else []

    labels = [b["key"] for b in buckets]
    counts = [b["doc_count"] for b in buckets]

    return render_template("chart.html", labels=labels, counts=counts)


if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)
```

**templates/index.html**
```html
<!DOCTYPE html>
<html>
<head>
    <title>Log Viewer</title>
    <style>
        body { font-family: Arial; margin: 20px; }
        table { border-collapse: collapse; width: 100%; margin-top: 20px; }
        th, td { border: 1px solid #ccc; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        input { margin-right: 10px; }
    </style>
</head>
<body>
    <h1>ğŸ” Log Viewer</h1>
    <form method="get">
        Mesaj Ara: <input type="text" name="q" value="{{ query }}">
        KullanÄ±cÄ±: <input type="text" name="user" value="{{ user }}">
        Seviye: <input type="text" name="level" value="{{ level }}">
        <button type="submit">Filtrele</button>
    </form>

    <table>
        <tr>
            <th>Zaman</th>
            <th>KullanÄ±cÄ±</th>
            <th>IP</th>
            <th>Seviye</th>
            <th>Mesaj</th>
        </tr>
        {% for log in logs %}
        <tr>
            <td>{{ log["@timestamp"] }}</td>
            <td>{{ log["user"] }}</td>
            <td>{{ log["ip"] }}</td>
            <td>{{ log["level"] }}</td>
            <td>{{ log["message"] }}</td>
        </tr>
        {% endfor %}
    </table>
</body>
</html>

```
**templates/errors.html**
```html
<!DOCTYPE html>
<html>
<head>
    <title>ERROR LoglarÄ±</title>
    <style>
        body { font-family: sans-serif; padding: 20px; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #aaa; padding: 8px; text-align: left; }
        th { background-color: #f44336; color: white; }
        tr:nth-child(even) { background-color: #f9f9f9; }
        input { margin-right: 10px; }
    </style>
</head>
<body>
    <h1>ğŸš¨ ERROR LoglarÄ±</h1>

    <form method="get">
        KullanÄ±cÄ±: <input type="text" name="user" value="{{ user }}">
        IP: <input type="text" name="ip" value="{{ ip }}">
        <button type="submit">Filtrele</button>
    </form>

    <table>
        <tr>
            <th>Zaman</th>
            <th>KullanÄ±cÄ±</th>
            <th>IP</th>
            <th>Mesaj</th>
        </tr>
        {% for log in logs %}
        <tr>
            <td>{{ log["@timestamp"] }}</td>
            <td>{{ log["user"] }}</td>
            <td>{{ log["ip"] }}</td>
            <td>{{ log["message"] }}</td>
        </tr>
        {% endfor %}
    </table>

    <p>{{ logs|length }} kayÄ±t bulundu.</p>
</body>
</html>

```
**templates/chart.html**
```
<!DOCTYPE html>
<html>
<head>
    <title>ERROR Log GrafiÄŸi</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: sans-serif; padding: 20px; }
        canvas { max-width: 800px; margin: auto; display: block; }
    </style>
</head>
<body>
    <h2>ğŸš¨ KullanÄ±cÄ±lara GÃ¶re ERROR Log SayÄ±sÄ±</h2>
    <canvas id="errorChart"></canvas>

    <script>
        const ctx = document.getElementById('errorChart').getContext('2d');
        const errorChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: {{ labels|tojson }},
                datasets: [{
                    label: 'ERROR Log SayÄ±sÄ±',
                    data: {{ counts|tojson }},
                    backgroundColor: 'rgba(255, 99, 132, 0.7)'
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: { beginAtZero: true }
                }
            }
        });
    </script>
</body>
</html>
```

Ä°lk Ã¶ncelikle loglarÄ±n Ã¼retilmesi amacÄ±yla ``python3 app_log_producer.py`` komutu kullanÄ±lÄ±r.

![Logstash](./img/91.png)

log Ã¼retme iÅŸlemi baÅŸarÄ±lÄ± bir ÅŸekilde baÅŸlatÄ±ldÄ±ÄŸÄ±nda Flask Web server 'Ä±n baÅŸlatÄ±lmasÄ± amacÄ±yla ``python3 app.py`` komutu ile baÅŸlatÄ±lÄ±r.

![Logstash](./img/92.png)

Web browser Ã¼zerinden ``http://localhost:5000/`` adresine baÄŸlanÄ±lÄ±r;

![Logstash](./img/93.png)

GÃ¶rselde gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi Elasticsearch Ã¼zerinden alÄ±nan log verileri bir tablo olarak gÃ¶rÃ¼lmektedir. Filterlar kullanÄ±larak istenilen loglar gÃ¶rÃ¼lebilemektedir. ``http://localhost:5000/errors`` adresi Ã¼zerinden ise sadece ``ERROR`` seviyesinde olan loglar gÃ¶rÃ¼ntÃ¼lenir.

![Logstash](./img/94.png)

Log seviyesi ``ERROR`` seviyesinde olanlarÄ±n kaÃ§ adet olduÄŸunu gÃ¶steren bir tabloyu ise ``http://localhost:5000/error-chart`` adresi Ã¼zerinden ulaÅŸabilirsiniz.

![Logstash](./img/95.png)